services:
  devcontainer:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - LLAMA_INDEX_CACHE_DIR=/root/.cache
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 2gb
    networks:
      - rgd-chatbot
    volumes:
      - ..:/workspaces:cached
      - /var/run/docker.sock:/var/run/docker.sock
      - ~/.ssh:/root/.ssh:cached
      - ~/.gitconfig:/root/.gitconfig:cached
      - ~/.wakatime.cfg:/root/.wakatime.cfg:cached
      - ~/.cache:/root/.cache:cached
      - ~/Github/bioin-401-project/data:/data:cached
    command: sleep infinity

  app:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - LLAMA_INDEX_CACHE_DIR=/root/.cache
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 2gb
    networks:
      - rgd-chatbot
    ports:
      - 8000:8000
    volumes:
      - ..:/workspaces:cached
      - /var/run/docker.sock:/var/run/docker.sock
      - ~/.cache:/root/.cache:cached
      - ~/Github/bioin-401-project/data:/data:cached
    working_dir: /workspaces/rgd-chatbot
    command: chainlit run -hw src/app.py

  neo4j:
    image: neo4j:5.16.0
    restart: unless-stopped
    volumes:
      - ~/Github/bioin-401-project/data/neo4j:/data:cached
    networks:
      - rgd-chatbot
    ports:
      - 7474:7474
      - 7687:7687
    environment:
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_PLUGINS=["apoc"]

  ollama:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    networks:
      - rgd-chatbot
    volumes:
      - ollama:/root/.ollama
    ports:
      - 11434:11434
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest

  nginx-proxy-manager:
    image: 'docker.io/jc21/nginx-proxy-manager:latest'
    restart: unless-stopped
    ports:
      - '80:80'
      - '81:81'
      - '443:443'
    volumes:
      - ~/Github/bioin-401-project/data/nginx-proxy-manager/data:/data
      - ~/Github/bioin-401-project/data/nginx-proxy-manager/letsencrypt:/etc/letsencrypt

  namecheap-ddns:
    image: alpine:3.19.1
    command: wget http://dynamicdns.park-your-domain.com/update?host=${DDNS_HOST}&domain=${DDNS_DOMAIN}&password=${DDNS_PASSWORD}

  rathole-client:
    build:
      context: rathole
    restart: unless-stopped
    network_mode: host
    volumes:
      - ./config/client.toml.tmpl:/app/client.toml.tmpl
    command: bash -c "sed s/RATHOLE_TOKEN/${RATHOLE_TOKEN}/g client.toml.tmpl > client.toml && ./rathole client.toml"

  rathole-server:
    build:
      context: rathole
    restart: unless-stopped
    network_mode: host
    volumes:
      - ./config/server.toml.tmpl:/app/server.toml.tmpl
    command: bash -c "sed s/RATHOLE_TOKEN/${RATHOLE_TOKEN}/g server.toml.tmpl > server.toml && ./rathole server.toml"

networks:
  rgd-chatbot:
    name: rgd-chatbot

volumes:
  ollama:
